import requests
from bs4 import BeautifulSoup as bs
import IPy
from urlparse import *
from optparse import OptionParser
import threading


mutex = threading.Lock()



def get_args():
    opt = OptionParser()
    opt.add_option('-i','--ip',action = 'store',type = "string" ,dest = 'ip')
    opt.add_option('-s','--save',action = 'store',type = "string" ,dest = 'file')
    opt_handle,args_handle = opt.parse_args()
    ip = opt_handle.ip
    save_file = opt_handle.file
    return ip,save_file



def req_bing(ip,filename):
    result_domain = []
    num = 1
    page = 0
    change_page = ""
    while True:
        url = "https://www.bing.com/search?q=ip%3a" + str(ip) + change_page
        result_url = bing(url)
        for url in result_url:
            domain = urlparse(url).netloc
            if domain not in result_domain:
                result_domain.append(domain)
        if len(result_url) >= 10:
            page = page + len(result_url) + 1
            change_page = "&first=%s&FORM=PERE" % page
            print change_page
            result_url = 0
        else:
            break
    if len(result_domain) != 0:
        for domain_s in result_domain:
            print str(ip),domain_s

            mutex.acquire()
            file_handle = open(filename,"a+")
            file_handle.write(str(ip) + "\t" + domain_s+"\n")
            file_handle.close()
            mutex.release()

def bing(url):
    result_url = list()
    req = requests.get(url)
    handle = bs(req.text)
    result_b = handle.find_all(class_="b_algo")
    for i in result_b:
        result_url.append(i.a.attrs["href"]+"\t"+i.a.get_text())
    return result_url



def main():
    ip_range,filename = get_args()
    final_txt = {}
    print filename,ip_range
    t_list = list()
    for ip in IPy.IP(ip_range):
        t = threading.Thread(target=req_bing,args=(ip,filename))
        t_list.append(t)


    for t in t_list:
        t.start()

    for t in t_list:
        t.join()





main()
